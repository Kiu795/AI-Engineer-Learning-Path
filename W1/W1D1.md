# W1D1

***

## 1.向量和矩阵

### 1.1 基本概念

**向量就是一组数字，可以理解成一个“列表”：**

列向量：
$$
\begin{bmatrix}1\\2\\3\end{bmatrix}
$$
一维向量：
$$
\begin{bmatrix}1&2&3\end{bmatrix}
$$
用途：

+ 表示特征（如一个样本的多个特征：身高、体重、年龄）
+ 表示词向量
+ ...

**矩阵是一个“二位的数字表格”：**
$$
A = \begin{bmatrix}1&2\\3&4\end{bmatrix}
$$
用途：

+ 把输入向量转变成输出向量e.g.神经网络的权重`W` 就是矩阵
+ 数据集（m行样本,n列特征）

### 1.2 基本运算

+ **矩阵加减**：

$$
\begin{bmatrix}1&2\\3&4\end{bmatrix} + \begin{bmatrix}1&2\\3&4\end{bmatrix} = \begin{bmatrix}2&4\\6&8\end{bmatrix}
$$

+ **矩阵转置**：

$$
A = \begin{bmatrix}1&2&3\end{bmatrix} \Rightarrow A^T = \begin{bmatrix}1\\2\\3\end{bmatrix}
$$

+ **矩阵乘法：**

$$
A = \begin{bmatrix}1&2\end{bmatrix}\\
B = \begin{bmatrix}3\\4\end{bmatrix}\\
AB = 1 \times 3 + 2 \times 4 = 11
$$

神经网络中：
$$
y = Wx
$$
就是矩阵乘法。

### 1.3 单位矩阵

$$
I = \begin{bmatrix}1&0\\0&1\end{bmatrix}\\ \\
IA = AI = A
$$

神经网络中：

+ 初始化残差结构
+ 计算单位变换
+ 理解反向传播中的雅可比矩阵
